{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769347a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84504d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!\n",
      "Available models: models=[Model(model='gemma3n:latest', modified_at=datetime.datetime(2025, 6, 29, 15, 48, 4, 292582, tzinfo=TzInfo(-04:00)), digest='15cb39fd9394fd2549f6df9081cfc84dd134ecf2c9c5be911e5629920489ac32', size=7547589116, details=ModelDetails(parent_model='', format='gguf', family='gemma3n', families=['gemma3n'], parameter_size='6.9B', quantization_level='Q4_K_M')), Model(model='llama3.1:8b', modified_at=datetime.datetime(2025, 2, 8, 11, 17, 43, 11404, tzinfo=TzInfo(-05:00)), digest='46e0c10c039e019119339687c3c1757cc81b9da49709a3b3924863ba87ca666e', size=4920753328, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_K_M')), Model(model='llama3.2:3b', modified_at=datetime.datetime(2025, 2, 3, 9, 32, 11, 979843, tzinfo=TzInfo(-05:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]\n",
      "INFO     [browser_use.agent.service] 💾 File system path: /var/folders/tt/r2rqxymj7j9352l2tmk5zj9c0000gn/T/browser_use_agent_068726cd-02f1-722b-8000-9bfec7dbb222\n",
      "INFO     [browser_use.Agent🅰 b222 on 🆂 b222 🅟 76] 🧠 Starting a browser-use agent 0.5.4 with base_model=llama3.1:latest +vision extraction_model=llama3.1:latest +file_system\n",
      "INFO     [browser_use.Agent🅰 b222 on 🆂 b222 🅟 76] 🚀 Starting task: Compare the price of gpt-4o and DeepSeek-V3\n",
      "INFO     [browser_use.BrowserSession🆂 b222:None #36] 🎭 Launching new local browser playwright:chromium keep_alive=False user_data_dir= ~/.config/browseruse/profiles/default\n",
      "INFO     [browser_use.BrowserSession🆂 b222:None #36]  ↳ Spawning Chrome subprocess listening on CDP http://127.0.0.1:52342/ with user_data_dir= ~/.config/browseruse/profiles/default\n",
      "INFO     [browser_use.BrowserSession🆂 b222:52342 #36] 🌎 Connecting to newly spawned browser via CDP http://127.0.0.1:52342/ -> browser_pid=76164 (local)\n",
      "INFO     [browser_use.BrowserSession🆂 b222:52342 #36] ➡️ Page navigation [0]about:blank took 0.52s\n",
      "WARNING  [browser_use.BrowserSession🆂 b222:52342 #36] ▫️ Sending LLM 1px placeholder instead of real screenshot of: about:blank (page empty)\n",
      "INFO     [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] 📍 Step 2: Evaluating page with 0 interactive elements on: about:blank\n",
      "ERROR    [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] ❌ Result failed 1/3 times:\n",
      " ('model \"llama3.1:latest\" not found, try pulling it first (status code: 404)', 502)\n",
      "INFO     [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] 📍 Step 1: Ran 1 actions in 4.02s: ❌ 1\n",
      "INFO     [browser_use.BrowserSession🆂 b222:52342 #36] ➡️ Page navigation [0]about:blank took 0.53s\n",
      "WARNING  [browser_use.BrowserSession🆂 b222:52342 #36] ▫️ Sending LLM 1px placeholder instead of real screenshot of: about:blank (page empty)\n",
      "INFO     [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] 📍 Step 2: Evaluating page with 0 interactive elements on: about:blank\n",
      "ERROR    [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] ❌ Result failed 2/3 times:\n",
      " ('model \"llama3.1:latest\" not found, try pulling it first (status code: 404)', 502)\n",
      "INFO     [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] 📍 Step 1: Ran 1 actions in 0.76s: ❌ 1\n",
      "INFO     [browser_use.BrowserSession🆂 b222:52342 #36] ➡️ Page navigation [0]about:blank took 0.53s\n",
      "WARNING  [browser_use.BrowserSession🆂 b222:52342 #36] ▫️ Sending LLM 1px placeholder instead of real screenshot of: about:blank (page empty)\n",
      "INFO     [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] 📍 Step 2: Evaluating page with 0 interactive elements on: about:blank\n",
      "ERROR    [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] ❌ Result failed 3/3 times:\n",
      " ('model \"llama3.1:latest\" not found, try pulling it first (status code: 404)', 502)\n",
      "INFO     [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] 📍 Step 1: Ran 1 actions in 0.93s: ❌ 1\n",
      "ERROR    [browser_use.Agent🅰 b222 on 🆂 b222 🅟 20] ❌ Stopping due to 3 consecutive failures\n",
      "INFO     [browser_use.BrowserSession🆂 b222:52342 #36] 🛑 Closing cdp_url=http://127.0.0.1:52342/ browser context  <Browser type=<BrowserType name=chromium executable_path=/Users/nguyen/Library/Caches/ms-playwright/chromium-1179/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=138.0.7204.23>\n",
      "INFO     [browser_use.BrowserSession🆂 b222:52342 #36]  ↳ Killing browser_pid=76164 ~/Library/Caches/ms-playwright/chromium-1179/chrome-mac/Chromium.app/Contents/MacOS/Chromium (terminate() called)\n",
      "AgentHistoryList(all_results=[ActionResult(is_done=False, success=None, error='(\\'model \"llama3.1:latest\" not found, try pulling it first (status code: 404)\\', 502)', attachments=None, long_term_memory=None, extracted_content=None, include_extracted_content_only_once=False, include_in_memory=False), ActionResult(is_done=False, success=None, error='(\\'model \"llama3.1:latest\" not found, try pulling it first (status code: 404)\\', 502)', attachments=None, long_term_memory=None, extracted_content=None, include_extracted_content_only_once=False, include_in_memory=False), ActionResult(is_done=False, success=None, error='(\\'model \"llama3.1:latest\" not found, try pulling it first (status code: 404)\\', 502)', attachments=None, long_term_memory=None, extracted_content=None, include_extracted_content_only_once=False, include_in_memory=False)], all_model_outputs=[])\n"
     ]
    }
   ],
   "source": [
    "from browser_use.llm import ChatOpenAI, ChatOllama\n",
    "from browser_use import Agent\n",
    "from dotenv import load_dotenv\n",
    "from ollama import Client\n",
    "import sys\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# OLLAMA_HOST = \"http://192.168.1.183:11434\"\n",
    "OLLAMA_HOST = \"http://localhost:11434\"\n",
    "# Establish tunnel to remote ollama server: ssh -L 11434:localhost:11434 nguyen@192.168.1.183\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4.1\")\n",
    "client = Client(host = OLLAMA_HOST)\n",
    "\n",
    "try:\n",
    "    models = client.list()\n",
    "    print(\"Connected successfully!\")\n",
    "    print(f\"Available models: {models}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "llm = ChatOllama(\n",
    "    host=OLLAMA_HOST,\n",
    "    model=\"llama3.1:latest\")\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        task=\"Compare the price of gpt-4o and DeepSeek-V3\",\n",
    "        llm=llm,\n",
    "    )\n",
    "    result = await agent.run()\n",
    "    print(result)\n",
    "\n",
    "# asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f4021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d078a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a33c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c38b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4bc51b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
