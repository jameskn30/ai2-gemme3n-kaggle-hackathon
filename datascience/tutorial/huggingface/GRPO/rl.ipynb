{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d599732",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfcfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "import os\n",
    "os.environ[\"TORCH_LOGS\"] = \"recompiles\"\n",
    "os.environ['TORCHDYNAMO_CACHE_SIZE_LIMIT'] = '999999999'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch._dynamo \n",
    "torch._dynamo.config.cache_size_limit = 64\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from pprint import pprint\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbdaf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mlabonne/smoltldr\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b039eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8398a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=\"all-linear\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa955c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward function\n",
    "ideal_length = 50\n",
    "\n",
    "\n",
    "def reward_len(completions, **kwargs):\n",
    "    return [-abs(ideal_length - len(completion)) for completion in completions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=\"GRPO\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_prompt_length=512,\n",
    "    max_completion_length=96,\n",
    "    num_generations=8,\n",
    "    num_train_epochs=1,\n",
    "    optim=\"adamw_8bit\",\n",
    "    # Enable bfloat16 (bf16) mixed precision training for faster computation and reduced memory usage on supported hardware (e.g., recent NVIDIA/Google TPUs/GPUs)\n",
    "    bf16=True,\n",
    "    report_to=[\"wandb\"],\n",
    "    remove_unused_columns=False,\n",
    "    logging_steps=1,\n",
    "    # use_vllm = True,\n",
    "    # vllm_mode=\"cocolate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57823179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    reward_funcs=[reward_len],\n",
    "    train_dataset=dataset[\"train\"],\n",
    ")\n",
    "\n",
    "# Train model\n",
    "wandb.init(project=\"GRPO\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "trainer.save_model(\"/output/model_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a619f21",
   "metadata": {},
   "source": [
    "# Using unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 1024\n",
    "lora_rank = 32 #larger rank -> better but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"google/gemma-3-1b-it\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    fast_inference=True,\n",
    "    max_lora_rank=lora_rank,\n",
    "    gpu_memory_utilization=0.6\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=lora_rank,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\"\n",
    "    ],\n",
    "    lora_alpha=lora_rank,\n",
    "    use_gradient_checkpointing='unsloth', #long context finetuning\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532acee",
   "metadata": {},
   "source": [
    "# Prep dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd681216",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "import re\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "\n",
    "# Helper functions to extract answers from different formats\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "\n",
    "# Function to prepare the GSM8K dataset\n",
    "def get_gsm8k_questions(split=\"train\") -> Dataset:\n",
    "    data = load_dataset(\"openai/gsm8k\", \"main\")[split]\n",
    "    data = data.map(\n",
    "        lambda x: {\n",
    "            \"prompt\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": x[\"question\"]},\n",
    "            ],\n",
    "            \"answer\": extract_hash_answer(x[\"answer\"]),\n",
    "        }\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "dataset = get_gsm8k_questions()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c282a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44677608",
   "metadata": {},
   "source": [
    "# Reward functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward function that checks if the answer is correct\n",
    "# The correctness_reward_func requires access to the original prompts and the ground-truth answers\n",
    "# because it needs to compare the model's extracted answer to the true answer for each prompt.\n",
    "# The other reward functions only evaluate the format or type of the completion, not its correctness,\n",
    "# so they only need the completions. Here, prompts are used for logging (to print the question),\n",
    "# and answer is used for correctness checking.\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    q = prompts[0][-1][\"content\"]  # Used for logging the question\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    print(\n",
    "        \"-\" * 20,\n",
    "        f\"Question:\\n{q}\",\n",
    "        f\"\\nAnswer:\\n{answer[0]}\",\n",
    "        f\"\\nResponse:\\n{responses[0]}\",\n",
    "        f\"\\nExtracted:\\n{extracted_responses[0]}\",\n",
    "    )\n",
    "    # Compare each extracted response to the corresponding answer\n",
    "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "\n",
    "# Reward function that checks if the answer is an integer\n",
    "def int_reward_func(completions, **kwargs) -> list[float]:\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
    "\n",
    "\n",
    "# Reward function that checks if the completion follows the strict format\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "\n",
    "# Reward function that checks if the completion follows a more relaxed format\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "\n",
    "# Reward function that counts XML tags and penalizes extra content\n",
    "def count_xml(text) -> float:\n",
    "    count = 0.0\n",
    "    if text.count(\"<reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n<answer>\\n\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"\\n</answer>\\n\")[-1]) * 0.001\n",
    "    if text.count(\"\\n</answer>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1) * 0.001\n",
    "    return count\n",
    "\n",
    "\n",
    "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "    return [count_xml(c) for c in contents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ec5e5",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "max_prompt_length = 256\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate=5e-6,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.99,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_steps=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,  # Increase to 4 for smoother training\n",
    "    num_generations=6,  # Decrease if out of memory\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_completion_length=max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps=250,\n",
    "    save_steps=250,\n",
    "    max_grad_norm=0.1,\n",
    "    report_to=\"none\",  # Can use Weights & Biases\n",
    "    output_dir=\"outputs\",\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs=[\n",
    "        xmlcount_reward_func,\n",
    "        soft_format_reward_func,\n",
    "        strict_format_reward_func,\n",
    "        int_reward_func,\n",
    "        correctness_reward_func,\n",
    "    ],\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806dce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a664626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3c6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
